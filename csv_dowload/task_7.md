## Реализовать загрузчик данных из файла `csv`, разделитель «;», который максимально быстро по времени загрузит файл в таблицу БД

### Реализация
Для реализации выбран метод бенмарка между несколькими способами загрузки данных "на лету", то есть: 
данные читаются из `csv`, затем грузятся в БД без предварительного создания в БД объекта
Методы чтения и вставки данных описаны в [csv_download/csv_download_bench.py](https://github.com/SolonnikovDV/mvTest/tree/master/csv_dowload)


#### 1. Использование `COPY` команды `PostgreSQL`
Данный метод требует предварительного анализа csv и создание соответствующего объекта в БД, 
что не удовлетворяет условиям загрузки данных "на лету"

#### 2. Использование pandas и SQLAlchemy
Обеспечивает хорошую скорость обработки и вставки данных среднего объема (до 5 млн строк)
Время выполнения: 16.544862985610962 секунд.

#### 3. Использование `Dask` для обработки больших данных
Данный метод хорошо себя показывает на больших объемах (от 5 млн строк), 
но проигрывает в скорости на объемах меньше библиотеке pandas
Время выполнения: 17.20434594154358 секунд.

#### 4. Использование `Pyarrow` для обработки больших данных
Метод неплохо себя зарекомендовавший на небольших и средних объемах данных, но его быстродействие сложно предугадать, 
по эффективности на больших объемах близок в библиотеке Dask
Время выполнения: 15.28524112701416 секунд.
